{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08caf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50b6053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is random change number: 0\n",
      "This is random change number: 1\n",
      "This is random change number: 2\n",
      "This is random change number: 3\n",
      "This is random change number: 4\n"
     ]
    }
   ],
   "source": [
    "#random change\n",
    "for i in range(5):\n",
    "    print(\"This is random change number:\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7c4bc",
   "metadata": {},
   "source": [
    "The following cells fit the autogluon model for the resting, active, walking, running classification  \n",
    "If not already done: make sure to run file in lab_data_processing for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c63b84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/elias/2025/sshfs_mounter_2025/data_elias/ECSS_2026/fft_lab\"\n",
    "ag_path_model = './base_ag_model'\n",
    "\n",
    "### get data from csv files\n",
    "df_list = []\n",
    "for f in os.listdir(root_dir):\n",
    "    df_list.append(pd.read_csv(os.path.join(root_dir, f)))\n",
    "    \n",
    "\n",
    "# use 20% of dataframes for testing\n",
    "test_size = int(0.2 * len(df_list))\n",
    "test_list = []\n",
    "for _ in range(test_size):\n",
    "    test_list.append(df_list.pop(np.random.randint(0, len(df_list))))\n",
    "    \n",
    "train_data = pd.concat(df_list, ignore_index=True)\n",
    "test_data = pd.concat(test_list, ignore_index=True)\n",
    "\n",
    "# set data labels of interest\n",
    "labels = [f\"acc_{i:.1f}\" for i in np.arange(1.0, 10.2, 0.2)] + ['label']\n",
    "\n",
    "# shuffle datasets\n",
    "train_data = shuffle(train_data, random_state=42).reset_index(drop=True)\n",
    "test_data = shuffle(test_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# reduce to labels of interest\n",
    "train_data = train_data[labels]\n",
    "test_data = test_data[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ec97c",
   "metadata": {},
   "source": [
    "The following cell selects the field data and adds it to the training set\n",
    "\n",
    "before running this cell, you might want to run ../extra_data_gathering/run_data_selector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e13e22e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field training examples 286997\n"
     ]
    }
   ],
   "source": [
    "def add_lab_data(train_data, include_field = True): \n",
    "    '''\n",
    "    Adds the field data for walking to the train data\n",
    "    param: train_data = training data from lab\n",
    "    param: include_field = boolean to include field data or not\n",
    "    return: train_data with field data added if include_field is True\n",
    "    '''\n",
    "    if include_field:\n",
    "        output_path = \"/home/elias/2025/sshfs_mounter_2025/data_elias/ECSS_2026/fft_field\"\n",
    "        \n",
    "        files = sorted(os.listdir(output_path))\n",
    "        \n",
    "        df_l = []\n",
    "        for f in files:\n",
    "            df = pd.read_csv(os.path.join(output_path, f))\n",
    "        \n",
    "            if len(df) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                df_l.append(df)\n",
    "            \n",
    "        field_data = pd.concat(df_l, ignore_index=True)\n",
    "        \n",
    "        print('field training examples', len(field_data))\n",
    "        \n",
    "        # only keep locomotion labels\n",
    "        #field_data = field_data[field_data['label'] == 'locomotion']\n",
    "        \n",
    "        # randomly choose 16000 examples to add to training data\n",
    "        #field_data = field_data.sample(n=16000, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        #train_data = pd.concat([train_data, field_data], ignore_index=True)\n",
    "        \n",
    "        return field_data\n",
    "    \n",
    "    else:\n",
    "        return train_data\n",
    "\n",
    "test_data = add_lab_data(train_data, include_field=True)\n",
    "\n",
    "#train_data = pd.concat([train_data, test_data.sample(n = 16000, random_state=42).reset_index(drop=True)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd98c886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment setup...\n",
      "NumPy version: 2.1.3\n",
      "Pandas version: 2.3.1\n",
      "Labels distribution:\n",
      "label\n",
      "locomotion        7209\n",
      "no locomotion    23796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data info:\n",
      "Features: 46\n",
      "Samples: 31005\n",
      "Feature columns: ['acc_1.0', 'acc_1.2', 'acc_1.4', 'acc_1.6', 'acc_1.8']...\n"
     ]
    }
   ],
   "source": [
    "# Disable Ray to avoid compatibility issues\n",
    "os.environ['AUTOGLUON_DISABLE_RAY'] = '1'\n",
    "\n",
    "# Also disable parallel processing that might cause issues\n",
    "os.environ['RAY_DISABLE_IMPORT_WARNING'] = '1'\n",
    "\n",
    "# Test environment setup\n",
    "print(\"Testing environment setup...\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Labels distribution:\")\n",
    "print(train_data['label'].value_counts().sort_index())\n",
    "\n",
    "# Check if data is properly prepared\n",
    "print(f\"\\nData info:\")\n",
    "print(f\"Features: {train_data.shape[1]-1}\")\n",
    "print(f\"Samples: {train_data.shape[0]}\")\n",
    "print(f\"Feature columns: {train_data.columns[:-1].tolist()[:5]}...\")  # Show first 5 feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2756a587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./base_ag_model\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35-Ubuntu SMP PREEMPT_DYNAMIC Mon May 20 15:51:52 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       26.11 GB / 31.35 GB (83.3%)\n",
      "Disk Space Avail:   19.98 GB / 96.28 GB (20.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/opt/code/physiological-studies/playground_Elias/ECSS_2026/models/base_ag_model\"\n",
      "Train Data Rows:    31005\n",
      "Train Data Columns: 46\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['locomotion', 'no locomotion']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = no locomotion, class 0 = locomotion\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (no locomotion) vs negative (locomotion) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26751.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['acc_1.0', 'acc_1.2', 'acc_1.4', 'acc_1.6', 'acc_1.8', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['acc_1.0', 'acc_1.2', 'acc_1.4', 'acc_1.6', 'acc_1.8', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t46 features in original data used to generate 46 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08063215610385421, Train Rows: 28505, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XGB': [{}],\n",
      "\t'RF': [{}],\n",
      "\t'NN_TORCH': [{}],\n",
      "}\n",
      "Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFitting with cpus=1, gpus=0, mem=0.0/26.1 GB\n",
      "\t0.9968\t = Validation score   (accuracy)\n",
      "\t14.23s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=1, gpus=0\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=1, gpus=0, mem=0.0/26.2 GB\n",
      "/opt/code/physiological-studies/.conda/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.996\t = Validation score   (accuracy)\n",
      "\t59.14s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 75.48s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 224006.8 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/code/physiological-studies/playground_Elias/ECSS_2026/models/base_ag_model\")\n"
     ]
    }
   ],
   "source": [
    "# Use simpler preset and disable problematic features\n",
    "predictor = TabularPredictor(label='label', eval_metric='accuracy', path=ag_path_model).fit(\n",
    "    train_data,\n",
    "    presets='medium_quality',\n",
    "    hyperparameters={\n",
    "        'XGB': {},\n",
    "        'RF': {},\n",
    "    },\n",
    "    num_cpus=1,\n",
    "    dynamic_stacking=False, \n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "918130ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_test  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         RandomForest    0.999742     0.9968    accuracy        0.161051       0.055261  14.230647                 0.161051                0.055261          14.230647            1       True          1\n",
      "1              XGBoost    0.999677     0.9972    accuracy        0.135568       0.010314   1.702432                 0.135568                0.010314           1.702432            1       True          2\n",
      "2  WeightedEnsemble_L2    0.999677     0.9972    accuracy        0.137500       0.011160   1.738023                 0.001932                0.000847           0.035592            2       True          4\n",
      "3       NeuralNetTorch    0.999258     0.9960    accuracy        0.394089       0.041509  59.136271                 0.394089                0.041509          59.136271            1       True          3\n"
     ]
    }
   ],
   "source": [
    "# gets and stores leaderboard in csv\n",
    "leader = predictor.leaderboard(train_data, silent= False)\n",
    "leader_df = pd.DataFrame(leader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa741ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy results:\n",
      "       total_accuracy  locomotion  no locomotion\n",
      "train        0.999677    0.998752       0.999958\n",
      "test         0.930013    0.919238       0.995256\n"
     ]
    }
   ],
   "source": [
    "# load model for evaluation\n",
    "classification_model = TabularPredictor.load(ag_path_model)\n",
    "\n",
    "# predictions for train, validation, and test sets\n",
    "predictions_train = classification_model.predict_proba(train_data.drop(columns=['label']))\n",
    "predictions_test = classification_model.predict_proba(test_data.drop(columns=['label']))\n",
    "\n",
    "# gets max probability class for each sample\n",
    "predictions_train = pd.Series(np.argmax(predictions_train.values, axis=1))\n",
    "predictions_test = pd.Series(np.argmax(predictions_test.values, axis=1))\n",
    "\n",
    "# calculate accuracy for each dataset\n",
    "def label_from_index(index):\n",
    "    return predictor.class_labels[index]\n",
    "predictions_train = predictions_train.apply(label_from_index)\n",
    "predictions_test = predictions_test.apply(label_from_index)\n",
    "\n",
    "# prediction df\n",
    "results_df = pd.DataFrame({\n",
    "    'train_true': train_data['label'],\n",
    "    'train_pred': predictions_train,\n",
    "    'test_true': test_data['label'],\n",
    "    'test_pred': predictions_test\n",
    "})\n",
    "\n",
    "# calculate accuracies\n",
    "l = []\n",
    "for splits in ['train', 'test']:\n",
    "    set_list = []\n",
    "    true_labels = results_df[f'{splits}_true'].dropna().values\n",
    "    pred_labels = results_df[f'{splits}_pred'].dropna().values\n",
    "    \n",
    "    for metric in ['total_accuracy', 'locomotion', 'no locomotion']:\n",
    "        if metric == 'total_accuracy':\n",
    "            set_list.append((true_labels == pred_labels).mean())\n",
    "        else:\n",
    "            mask = true_labels == metric\n",
    "            set_list.append((true_labels[mask] == pred_labels[mask]).mean())\n",
    "            \n",
    "    l.append(set_list)\n",
    "    \n",
    "accuracy_df = pd.DataFrame(l, columns=['total_accuracy', 'locomotion', 'no locomotion'], index=['train',  'test'])\n",
    "print(\"\\nAccuracy results:\")\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde1fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
